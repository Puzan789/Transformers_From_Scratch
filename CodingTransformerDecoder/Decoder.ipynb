{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  .\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q,k,v,mask=None):\n",
    "    #q : 30 x 8 x 200 k : 30 x 8 x 200 v : 30 x 8 x 200  mask : 200 x 200\n",
    "    d_k=q.size(-1)\n",
    "    scaled=torch.matmul(q,k.transpose(-1,-2))/math.sqrt(d_k)#d-k is use for scale # 30 x8 x 200 x 200\n",
    "    print(f\"scaled.size = {scaled.size()}\")\n",
    "    if mask is not None:\n",
    "        scaled+=mask#30 x 8 x 200 x 200\n",
    "    attention=F.softmax(scaled,dim=-1)# 30 x 8 x 200 x 200\n",
    "    values=torch.matmul(attention,v)# 30 x 8 x 200 x 64\n",
    "    return values,attention\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,parameters_shape,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameters_shape = parameters_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        dims=[-(i+1) for i in range(len(self.parameters_shape))] # it takes last layer\n",
    "        print(f\"dims={dims}\")\n",
    "        mean=inputs.mean(dim=dims,keepdim=True)\n",
    "        print(f\"Mean({mean.size()})\")\n",
    "        var=((inputs-mean)**2).mean(dim=dims,keepdim=True)\n",
    "        std=(var+self.eps).sqrt()\n",
    "        print(f\"Standard Deviation({std.size()})\")\n",
    "        y=(inputs-mean)/std\n",
    "        print(f\"y.size = {y.size()}\")\n",
    "        out=self.gamma * y + self.beta\n",
    "        print(f\"out : {out.size()}\")\n",
    "        return out\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self,d_model,hidden,drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "    def forward(self,x):\n",
    "        x=self.linear1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model,num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_model//num_heads\n",
    "        self.qkv_layer=nn.Linear(d_model,3*d_model)# it means map d_model to 3*d_model which means 512 to 1536\n",
    "        self.linear_layer=nn.Linear(d_model,d_model)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        batch_size,sequence_length,d_model=x.size()#it is a target sentence 30 x 200 x512\n",
    "        print(f'x.size:{x.size}')\n",
    "        qkv=self.qkv_layer(x)# 30 x 200 x 1536\n",
    "        qkv=qkv.reshape(batch_size,sequence_length,self.num_heads,3*self.head_dim)# we reshaping because we want to perform multihead attention\n",
    "        # 300 x 200 x  8 x 192\n",
    "        print(f'qkv.shape:{qkv.size()}')\n",
    "        qkv=qkv.permute(0,2,1,3)#30 x 8 x 200 x 192\n",
    "        print(f'qkv after permutation : {qkv.size()}')\n",
    "        q,k,v=qkv.chunk(3,dim=-1)#30 x8 x 200 x 64  for single q k and v\n",
    "        print(f'q.shape:{q.size()}, k.shape:{k.size()}, v.shape:{v.size()}')\n",
    "        values,attention=scaled_dot_product(q,k,v,mask)\n",
    "        print(f'values.shape:{values.size()}, attention.shape:{attention.size()}')\n",
    "        values=values.reshape(batch_size,sequence_length,self.num_heads*self.head_dim)# 30 x 200 x 512 # concatenating together 8 heads\n",
    "        out =self.linear_layer(values)# 30 x 200 x 512 # \n",
    "        print(f\"out after passsing through linear layer {out.size()}\")\n",
    "        return out\n",
    "class MultiheadCrossAttention(nn.Module):\n",
    "    def __init__(self,d_model,num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim=d_model//num_heads\n",
    "        self.kv_layer=nn.Linear(d_model,2*d_model)\n",
    "        self.q_layer=nn.Linear(d_model,d_model)\n",
    "        self.linear_layer=nn.Linear(d_model,d_model)\n",
    "    def forward(self,x,y,mask=None):\n",
    "        batch_size,sequence_length,d_model=x.size()\n",
    "        print(f\"x.size:{x.size()}\")\n",
    "        kv=self.kv_layer(x)# 30 x 200 x 1024\n",
    "        print(f\"kv.size:{kv.size()}\")\n",
    "        q=self.q_layer(y)\n",
    "        print(f\"q.size:{q.size()}\")\n",
    "        kv=kv.reshape(batch_size,sequence_length,self.num_heads,2*self.head_dim)#30 x 200 x 8 x 128\n",
    "        q=q.reshape(batch_size,sequence_length,self.num_heads,self.head_dim)# 30 x 200 x 8 x 64\n",
    "        kv=kv.permute(0,2,1,3)#30 x 8 x 200 x 128\n",
    "        q=q.permute(0,2,1,3)#30 x 8 x 200 x 64\n",
    "        k,v=kv.chunk(2,dim=-1)\n",
    "        values,attention=scaled_dot_product(q,k,v,mask)\n",
    "        print(f\"values: {values.size()},attention:{attention.size()}\")\n",
    "        values=values.reshape(batch_size,sequence_length,d_model)\n",
    "        out=self.linear_layer(values)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,num_heads,drop_prob):\n",
    "        super().__init__()\n",
    "        self.self_attention=MultiHeadAttention(d_model=d_model,num_heads=num_heads)\n",
    "        self.norm1=LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout1=nn.Dropout(p=drop_prob)\n",
    "        self.encoder_decoder_attention=MultiheadCrossAttention(d_model=d_model,num_heads=num_heads)\n",
    "        self.norm2=LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout2=nn.Dropout(p=drop_prob)\n",
    "        self.ffn=PositionWiseFeedForward(d_model=d_model,hidden=ffn_hidden,drop_prob=drop_prob)\n",
    "        self.norm3=LayerNormalization(parameters_shape=[d_model])\n",
    "        self.dropout3=nn.Dropout(p=drop_prob)\n",
    "    def forward(self,x,y,decoder_mask):\n",
    "        _y=y # Residual connection\n",
    "        print(\"Masked Self Attention\")\n",
    "        y=self.self_attention(y,mask=decoder_mask)\n",
    "        print(\"Drop out 1\")\n",
    "        y=self.dropout1(y)\n",
    "        print(\"Add and Normalization 1\")\n",
    "        y=self.norm1(y+_y)\n",
    "        _y=y# Another Residual\n",
    "        print(\"Cross Attention\")\n",
    "        y=self.encoder_decoder_attention(y,x,mask=None)\n",
    "        print(\"Drop out 2\")\n",
    "        y=self.dropout2(y)\n",
    "        print(\"Add and Normalization 2\")\n",
    "        y=self.norm2(y+_y)\n",
    "        _y=y \n",
    "        print(f\"Feed forward 1\")\n",
    "        y=self.ffn(y)\n",
    "        print(\"Drop out 3\")\n",
    "        y=self.dropout3(y)\n",
    "        print(\"Add and Normalization 3\")\n",
    "        y=self.norm3(y+_y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDecoder(nn.Sequential):# we using sequential decoder because we have more than one parameter in Decoder forward .\n",
    "        def forward(self, *inputs):\n",
    "            x,y,mask = inputs\n",
    "            for module in self._modules.values():\n",
    "                y=module(x,y,mask)# our same value of x is feeded in decoder layer but y is calculated which produce new word or tokens and it is again feeded to decoder.\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,d_model,ffn_hidden,num_heads,drop_prob,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.layers =SequentialDecoder(*[DecoderLayer(d_model,ffn_hidden,num_heads,drop_prob) for _ in range(num_layers)])\n",
    "        # nn.sequential is not used here because forward contain more than one parameter\n",
    "\n",
    "    def forward(self,x,y,mask):#input sentences,target sentence,mask\n",
    "        # x :30 x 200 x512\n",
    "        # y:30 x 200 x512\n",
    "        # Mask : 200 x 200\n",
    "        y=self.layers(x,y,mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Self Attention\n",
      "x.size:<built-in method size of Tensor object at 0x0000025737D52800>\n",
      "qkv.shape:torch.Size([30, 200, 8, 192])\n",
      "qkv after permutation : torch.Size([30, 8, 200, 192])\n",
      "q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape:torch.Size([30, 8, 200, 64])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values.shape:torch.Size([30, 8, 200, 64]), attention.shape:torch.Size([30, 8, 200, 200])\n",
      "out after passsing through linear layer torch.Size([30, 200, 512])\n",
      "Drop out 1\n",
      "Add and Normalization 1\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Cross Attention\n",
      "x.size:torch.Size([30, 200, 512])\n",
      "kv.size:torch.Size([30, 200, 1024])\n",
      "q.size:torch.Size([30, 200, 512])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values: torch.Size([30, 8, 200, 64]),attention:torch.Size([30, 8, 200, 200])\n",
      "Drop out 2\n",
      "Add and Normalization 2\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Feed forward 1\n",
      "Drop out 3\n",
      "Add and Normalization 3\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Masked Self Attention\n",
      "x.size:<built-in method size of Tensor object at 0x0000025737D4D6D0>\n",
      "qkv.shape:torch.Size([30, 200, 8, 192])\n",
      "qkv after permutation : torch.Size([30, 8, 200, 192])\n",
      "q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape:torch.Size([30, 8, 200, 64])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values.shape:torch.Size([30, 8, 200, 64]), attention.shape:torch.Size([30, 8, 200, 200])\n",
      "out after passsing through linear layer torch.Size([30, 200, 512])\n",
      "Drop out 1\n",
      "Add and Normalization 1\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Cross Attention\n",
      "x.size:torch.Size([30, 200, 512])\n",
      "kv.size:torch.Size([30, 200, 1024])\n",
      "q.size:torch.Size([30, 200, 512])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values: torch.Size([30, 8, 200, 64]),attention:torch.Size([30, 8, 200, 200])\n",
      "Drop out 2\n",
      "Add and Normalization 2\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Feed forward 1\n",
      "Drop out 3\n",
      "Add and Normalization 3\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Masked Self Attention\n",
      "x.size:<built-in method size of Tensor object at 0x0000025737D4CCD0>\n",
      "qkv.shape:torch.Size([30, 200, 8, 192])\n",
      "qkv after permutation : torch.Size([30, 8, 200, 192])\n",
      "q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape:torch.Size([30, 8, 200, 64])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values.shape:torch.Size([30, 8, 200, 64]), attention.shape:torch.Size([30, 8, 200, 200])\n",
      "out after passsing through linear layer torch.Size([30, 200, 512])\n",
      "Drop out 1\n",
      "Add and Normalization 1\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Cross Attention\n",
      "x.size:torch.Size([30, 200, 512])\n",
      "kv.size:torch.Size([30, 200, 1024])\n",
      "q.size:torch.Size([30, 200, 512])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values: torch.Size([30, 8, 200, 64]),attention:torch.Size([30, 8, 200, 200])\n",
      "Drop out 2\n",
      "Add and Normalization 2\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Feed forward 1\n",
      "Drop out 3\n",
      "Add and Normalization 3\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Masked Self Attention\n",
      "x.size:<built-in method size of Tensor object at 0x0000025737D4C6E0>\n",
      "qkv.shape:torch.Size([30, 200, 8, 192])\n",
      "qkv after permutation : torch.Size([30, 8, 200, 192])\n",
      "q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape:torch.Size([30, 8, 200, 64])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values.shape:torch.Size([30, 8, 200, 64]), attention.shape:torch.Size([30, 8, 200, 200])\n",
      "out after passsing through linear layer torch.Size([30, 200, 512])\n",
      "Drop out 1\n",
      "Add and Normalization 1\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Cross Attention\n",
      "x.size:torch.Size([30, 200, 512])\n",
      "kv.size:torch.Size([30, 200, 1024])\n",
      "q.size:torch.Size([30, 200, 512])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values: torch.Size([30, 8, 200, 64]),attention:torch.Size([30, 8, 200, 200])\n",
      "Drop out 2\n",
      "Add and Normalization 2\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Feed forward 1\n",
      "Drop out 3\n",
      "Add and Normalization 3\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Masked Self Attention\n",
      "x.size:<built-in method size of Tensor object at 0x0000025737D45C20>\n",
      "qkv.shape:torch.Size([30, 200, 8, 192])\n",
      "qkv after permutation : torch.Size([30, 8, 200, 192])\n",
      "q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape:torch.Size([30, 8, 200, 64])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values.shape:torch.Size([30, 8, 200, 64]), attention.shape:torch.Size([30, 8, 200, 200])\n",
      "out after passsing through linear layer torch.Size([30, 200, 512])\n",
      "Drop out 1\n",
      "Add and Normalization 1\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Cross Attention\n",
      "x.size:torch.Size([30, 200, 512])\n",
      "kv.size:torch.Size([30, 200, 1024])\n",
      "q.size:torch.Size([30, 200, 512])\n",
      "scaled.size = torch.Size([30, 8, 200, 200])\n",
      "values: torch.Size([30, 8, 200, 64]),attention:torch.Size([30, 8, 200, 200])\n",
      "Drop out 2\n",
      "Add and Normalization 2\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n",
      "Feed forward 1\n",
      "Drop out 3\n",
      "Add and Normalization 3\n",
      "dims=[-1]\n",
      "Mean(torch.Size([30, 200, 1]))\n",
      "Standard Deviation(torch.Size([30, 200, 1]))\n",
      "y.size = torch.Size([30, 200, 512])\n",
      "out : torch.Size([30, 200, 512])\n"
     ]
    }
   ],
   "source": [
    "d_model=512\n",
    "num_heads=8\n",
    "drop_prob=0.1\n",
    "batch_size=30\n",
    "max_sequence_length=200\n",
    "ffn_hidden=2048\n",
    "num_layers=5\n",
    "x=torch.randn((batch_size,max_sequence_length,d_model))# input lang positional encoded\n",
    "y=torch.randn((batch_size,max_sequence_length,d_model))# target lang posiitonal encoded\n",
    "mask=torch.full([max_sequence_length,max_sequence_length],float('-inf'))\n",
    "mask=torch.triu(mask,diagonal=1)\n",
    "decoder=Decoder(d_model,ffn_hidden,num_heads,drop_prob,num_layers)\n",
    "out=decoder(x,y,mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
