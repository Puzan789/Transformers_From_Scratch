# ðŸŒŸ My Learning Journey with Transformers ðŸŒŸ

Welcome to my coding journey! Starting today, I am building a transformer from scratch. This repository contains  codes and documents from my learning process, with each step detailed in its own README file.

## ðŸš€ Journey Overview

1. **Self-Attention** - Understanding and implementing the core concept of self-attention in transformers. [Read more](Self_Attention/Readme.md)
2. **MultiHead-Attention** - Understanding and implementing the concept of Multihead Attention in transformers. [Read more](MultiHead_Attention/Readme.md)
3. **Positional_Encoding** - Understanding and implementing the  concept of Positional Encoding in transformers. [Read more](Positional_Encoding/Readme.md)
4. **Encoder layer** - Understanding and Implementing  the Encoder layer. [Read more](CodingTransformerEncoder/Readme.md)


